experiment_name: "transformer3-angular-sincos"
project_name : "translation_and_rotation_cifar"

model:
  name: "transformer3-angular-sincos"
  type: "transformer"
  #stuff specific to transformer model
  image_size: 48
  patch_size: 8
  in_chans: 6 
  embedding_dimension: 64 
  depth: 4 #added one layer of depth
  number_heads: 8
  mlp_ratio: 4.0
  dropout: 0.1
  activation: "relu" 
  unit_norm: True 
  #general stuff
  task: "regression"
  use_sincos_encoding: true
  dataset: "translated_cifar" 

training:
  num_epochs: 10 
  batch_size: 128 
  learning_rate: 0.001
  loss: "angular" #using the angular loss function to take into account the circular nature of the data
  optimizer: "adam"